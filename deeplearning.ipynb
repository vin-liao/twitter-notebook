{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_1.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "L3sbjocVhn4P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#the \"!\" is used for executing commands in terminal\n",
        "!pip install -q keras\n",
        "!pip install -U -q PyDrive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GlobalMaxPooling1D, CuDNNGRU, Dropout, BatchNormalization, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import keras.optimizers\n",
        "import os\n",
        "from google.colab import files\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from html import unescape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HXZVblNlknd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#change this value depending on what you need\n",
        "use_existing_weights = False\n",
        "filepath = 'weights_best.hdf5'\n",
        "model_name = 'rnn_model_twitter.h5'\n",
        "\n",
        "def authenticate_drive():\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  \n",
        "  return drive\n",
        "\n",
        "if use_existing_weights:\n",
        "  drive = authenticate_drive()\n",
        "    \n",
        "  #download weights from google drive\n",
        "  weight_id = '1cM_aXUHcVylDRu9n57L-6Q0L8XmdCvJU'\n",
        "  weight_drive_file = drive.CreateFile({'id': weight_id})\n",
        "  weight_drive_file.GetContentFile(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBoN65yiZ6yO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip && unzip glove.twitter.27B.zip -d data/\n",
        "!wget http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip && unzip Sentiment-Analysis-Dataset.zip -d data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQY_M0oec_Zd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#load data to the working environment\n",
        "data_path = os.path.join(os.path.expanduser('~'), 'data', 'Sentiment Analysis Dataset.csv')\n",
        "dataset = pd.read_csv(data_path, error_bad_lines=False, encoding='utf-8')\n",
        "dataset.dropna(axis=0, inplace=True)\n",
        "dataset = dataset.rename(index=str, columns={\"SentimentText\": \"text\", \"Sentiment\": \"sentiment\"})\n",
        "\n",
        "embedding_path = os.path.join(os.path.expanduser('~'), 'data', 'glove.twitter.27B.200d.txt')\n",
        "dim_size = 200\n",
        "\n",
        "#shuffle data\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#take sample of it\n",
        "dataset = dataset.sample(frac=0.01, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odC1vmZ-kXRe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#preprocess dataset\n",
        "eyes = r\"[8:=;]\"\n",
        "nose = r\"['`\\-]?\"\n",
        "\n",
        "#decode html entities\n",
        "dataset.text = dataset.text.apply(lambda x: unescape(x))\n",
        "\n",
        "#fix this\n",
        "# ã?Ÿã?„ã?“ã‚Œã‚“ã?—ã‚…ã?† at index 1502\n",
        "\n",
        "dataset['text'] = dataset['text']\\\n",
        ".str.replace(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>')\\\n",
        "  .str.replace(r'@\\w+', '<user>')\\\n",
        "  .str.replace(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>')\\\n",
        "  .str.replace(r'{}{}p+'.format(eyes, nose), '<lolface>')\\\n",
        "  .str.replace(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>')\\\n",
        "  .str.replace(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>')\\\n",
        "  .str.replace(r'/',' / ')\\\n",
        "  .str.replace(r'<3','<heart>')\\\n",
        "  .str.replace(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>')\\\n",
        "  .str.replace(r'#\\S+', '<hashtag>')\\\n",
        "  .str.replace(r'([!?.]){2,}', r'\\1 <repeat>')\\\n",
        "  .str.replace(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>')\n",
        "  \n",
        "#source: https://gist.github.com/tokestermw/cb87a97113da12acb388"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2IfnbVxkutx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#prep the dataset\n",
        "#filter these things from the text\n",
        "token = text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\]^_`{|}~\\t\\n')\n",
        "max_len = dataset['text'].str.len().max()\n",
        "\n",
        "#learn the vocabulary from all the text\n",
        "token.fit_on_texts(list(dataset['text']))\n",
        "vocab_size = len(token.word_index) + 1\n",
        "\n",
        "#this might produce some error, test these 2 lines\n",
        "x_train, x_val, y_train, y_val = train_test_split(dataset['text'], dataset['sentiment'], test_size=0.03, shuffle=False)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5)\n",
        "\n",
        "#encode\n",
        "x_train_enc = token.texts_to_sequences(x_train)\n",
        "x_test_enc = token.texts_to_sequences(x_test)\n",
        "\n",
        "#add zero padding\n",
        "x_train_enc_pad = sequence.pad_sequences(x_train_enc, maxlen=max_len)\n",
        "x_test_enc_pad = sequence.pad_sequences(x_test_enc, maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kiYcAzlqk-vB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#create embedding dictionary\n",
        "embeddings_index = dict()\n",
        "f = open(embedding_path)\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "#map the vocabulary to it's word embedding\n",
        "embedding_matrix = np.zeros((vocab_size, dim_size))\n",
        "for word, i in token.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArUMjvYwFSj0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "da2646c9-6d5b-43be-b99f-c7990ac3916f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519703915726,
          "user_tz": -420,
          "elapsed": 764,
          "user": {
            "displayName": "Vincent",
            "photoUrl": "//lh3.googleusercontent.com/-LlNb3300Jzo/AAAAAAAAAAI/AAAAAAAAAFI/S7-qu260Jj8/s50-c-k-no/photo.jpg",
            "userId": "104593263505885814568"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#checking if data works correctly\n",
        "index = random.randint(1, x_train.shape[0])\n",
        "\n",
        "print('Preprocessed sentence')\n",
        "print(dataset.iloc[index, 3], end='\\n\\n')\n",
        "print('Sentiment')\n",
        "print(y_train[index], end='\\n\\n')\n",
        "print('Encoded text')\n",
        "print(x_train_enc[index], end='\\n\\n')\n",
        "\n",
        "\n",
        "res = dict((v,k) for k,v in token.word_index.items())\n",
        "for num in x_train_enc[index]:\n",
        "  print(res.get(num), end=' ')\n",
        "\n",
        "print()\n",
        "print('Zero padding')\n",
        "print(x_train_enc_pad[index])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessed sentence\n",
            "Wanted Kate to win the Aprentice \n",
            "\n",
            "Sentiment\n",
            "0\n",
            "\n",
            "Encoded text\n",
            "[355, 1226, 3, 449, 4, 14404]\n",
            "\n",
            "wanted kate to win the aprentice \n",
            "Zero padding\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0   355  1226     3   449     4 14404]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rlaZzWaSlQpW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 116
            },
            {
              "item_id": 160
            },
            {
              "item_id": 292
            },
            {
              "item_id": 389
            },
            {
              "item_id": 521
            },
            {
              "item_id": 644
            },
            {
              "item_id": 726
            },
            {
              "item_id": 849
            },
            {
              "item_id": 940
            },
            {
              "item_id": 1010
            },
            {
              "item_id": 1099
            },
            {
              "item_id": 1217
            },
            {
              "item_id": 1306
            },
            {
              "item_id": 1418
            },
            {
              "item_id": 1498
            },
            {
              "item_id": 1617
            },
            {
              "item_id": 1711
            },
            {
              "item_id": 1806
            },
            {
              "item_id": 1894
            },
            {
              "item_id": 1997
            },
            {
              "item_id": 2110
            },
            {
              "item_id": 2197
            },
            {
              "item_id": 2304
            },
            {
              "item_id": 2383
            },
            {
              "item_id": 2488
            },
            {
              "item_id": 2615
            },
            {
              "item_id": 2728
            },
            {
              "item_id": 2819
            },
            {
              "item_id": 2927
            },
            {
              "item_id": 3033
            },
            {
              "item_id": 3142
            },
            {
              "item_id": 3224
            },
            {
              "item_id": 3350
            },
            {
              "item_id": 3462
            },
            {
              "item_id": 3582
            },
            {
              "item_id": 3711
            },
            {
              "item_id": 3836
            },
            {
              "item_id": 3945
            },
            {
              "item_id": 4073
            },
            {
              "item_id": 4183
            },
            {
              "item_id": 4282
            },
            {
              "item_id": 4398
            },
            {
              "item_id": 4497
            },
            {
              "item_id": 4537
            },
            {
              "item_id": 4584
            },
            {
              "item_id": 4660
            },
            {
              "item_id": 4787
            },
            {
              "item_id": 4893
            },
            {
              "item_id": 4988
            },
            {
              "item_id": 5093
            },
            {
              "item_id": 5168
            },
            {
              "item_id": 5206
            },
            {
              "item_id": 5248
            },
            {
              "item_id": 5286
            },
            {
              "item_id": 5313
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 10237
        },
        "outputId": "c2af7fdf-d7f4-4d9f-ba14-43fbb9f5d527",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519707728441,
          "user_tz": -420,
          "elapsed": 2032213,
          "user": {
            "displayName": "Vincent",
            "photoUrl": "//lh3.googleusercontent.com/-LlNb3300Jzo/AAAAAAAAAAI/AAAAAAAAAFI/S7-qu260Jj8/s50-c-k-no/photo.jpg",
            "userId": "104593263505885814568"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#deep learning\n",
        "finished_training = False\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, dim_size, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(CuDNNGRU(32, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(CuDNNGRU(16, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "if use_existing_weights:\n",
        "  model.load_weights(filepath)\n",
        "\n",
        "#hyperparameter is a mess, tune it\n",
        "#lr, batch_size, epoch, dropout, maybe some decay, hidden units is maybe too small\n",
        "opt = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "earlystop = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callback_lists = [earlystop, checkpoint]\n",
        "\n",
        "model.fit(x_train_enc_pad, y_train, epochs=300, batch_size=100, callbacks=callback_lists)\n",
        "scores = model.evaluate(x_test_enc_pad, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "model.save(model_name)\n",
        "finished_training = True"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "12628/12628 [==============================] - 16s 1ms/step - loss: 1.0142 - acc: 0.5672\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.01416, saving model to weights_best.hdf5\n",
            "Epoch 2/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.6336 - acc: 0.6433\n",
            "\n",
            "Epoch 00002: loss improved from 1.01416 to 0.63355, saving model to weights_best.hdf5\n",
            "Epoch 3/300\n",
            "11000/12628 [=========================>....] - ETA: 1s - loss: 0.5862 - acc: 0.6857"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.5849 - acc: 0.6869\n",
            "\n",
            "Epoch 00003: loss improved from 0.63355 to 0.58486, saving model to weights_best.hdf5\n",
            "Epoch 4/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.5524 - acc: 0.7188\n",
            "\n",
            "Epoch 00004: loss improved from 0.58486 to 0.55238, saving model to weights_best.hdf5\n",
            "Epoch 5/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.5282 - acc: 0.7357\n",
            "\n",
            "Epoch 00005: loss improved from 0.55238 to 0.52825, saving model to weights_best.hdf5\n",
            "Epoch 6/300\n",
            "  700/12628 [>.............................] - ETA: 14s - loss: 0.5272 - acc: 0.7486"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.5150 - acc: 0.7459\n",
            "\n",
            "Epoch 00006: loss improved from 0.52825 to 0.51497, saving model to weights_best.hdf5\n",
            "Epoch 7/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.5063 - acc: 0.7536\n",
            "\n",
            "Epoch 00007: loss improved from 0.51497 to 0.50629, saving model to weights_best.hdf5\n",
            "Epoch 8/300\n",
            "11900/12628 [===========================>..] - ETA: 0s - loss: 0.4945 - acc: 0.7639"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.4940 - acc: 0.7650\n",
            "\n",
            "Epoch 00008: loss improved from 0.50629 to 0.49401, saving model to weights_best.hdf5\n",
            "Epoch 9/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.4876 - acc: 0.7665\n",
            "\n",
            "Epoch 00009: loss improved from 0.49401 to 0.48757, saving model to weights_best.hdf5\n",
            "Epoch 10/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.4805 - acc: 0.7669\n",
            "\n",
            "Epoch 00010: loss improved from 0.48757 to 0.48047, saving model to weights_best.hdf5\n",
            "Epoch 11/300\n",
            "  700/12628 [>.............................] - ETA: 13s - loss: 0.4728 - acc: 0.7829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.4660 - acc: 0.7822\n",
            "\n",
            "Epoch 00011: loss improved from 0.48047 to 0.46600, saving model to weights_best.hdf5\n",
            "Epoch 12/300\n",
            "12628/12628 [==============================] - 15s 1ms/step - loss: 0.4666 - acc: 0.7787\n",
            "\n",
            "Epoch 00012: loss did not improve\n",
            "Epoch 13/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4577 - acc: 0.7843\n",
            "\n",
            "Epoch 00013: loss improved from 0.46600 to 0.45773, saving model to weights_best.hdf5\n",
            "Epoch 14/300\n",
            "  300/12628 [..............................] - ETA: 13s - loss: 0.4403 - acc: 0.7833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4542 - acc: 0.7873\n",
            "\n",
            "Epoch 00014: loss improved from 0.45773 to 0.45423, saving model to weights_best.hdf5\n",
            "Epoch 15/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4506 - acc: 0.7908\n",
            "\n",
            "Epoch 00015: loss improved from 0.45423 to 0.45063, saving model to weights_best.hdf5\n",
            "Epoch 16/300\n",
            "11800/12628 [===========================>..] - ETA: 0s - loss: 0.4420 - acc: 0.7975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4411 - acc: 0.7989\n",
            "\n",
            "Epoch 00016: loss improved from 0.45063 to 0.44107, saving model to weights_best.hdf5\n",
            "Epoch 17/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4350 - acc: 0.8014\n",
            "\n",
            "Epoch 00017: loss improved from 0.44107 to 0.43500, saving model to weights_best.hdf5\n",
            "Epoch 18/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4273 - acc: 0.8039\n",
            "\n",
            "Epoch 00018: loss improved from 0.43500 to 0.42735, saving model to weights_best.hdf5\n",
            "Epoch 19/300\n",
            "  700/12628 [>.............................] - ETA: 12s - loss: 0.4188 - acc: 0.8100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4213 - acc: 0.8082\n",
            "\n",
            "Epoch 00019: loss improved from 0.42735 to 0.42129, saving model to weights_best.hdf5\n",
            "Epoch 20/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4210 - acc: 0.8095\n",
            "\n",
            "Epoch 00020: loss improved from 0.42129 to 0.42103, saving model to weights_best.hdf5\n",
            "Epoch 21/300\n",
            "11800/12628 [===========================>..] - ETA: 0s - loss: 0.4135 - acc: 0.8132"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4121 - acc: 0.8146\n",
            "\n",
            "Epoch 00021: loss improved from 0.42103 to 0.41213, saving model to weights_best.hdf5\n",
            "Epoch 22/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.4090 - acc: 0.8184\n",
            "\n",
            "Epoch 00022: loss improved from 0.41213 to 0.40897, saving model to weights_best.hdf5\n",
            "Epoch 23/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3917 - acc: 0.8248\n",
            "\n",
            "Epoch 00023: loss improved from 0.40897 to 0.39168, saving model to weights_best.hdf5\n",
            "Epoch 24/300\n",
            "  700/12628 [>.............................] - ETA: 12s - loss: 0.3722 - acc: 0.8386"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3879 - acc: 0.8260\n",
            "\n",
            "Epoch 00024: loss improved from 0.39168 to 0.38793, saving model to weights_best.hdf5\n",
            "Epoch 25/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3864 - acc: 0.8314\n",
            "\n",
            "Epoch 00025: loss improved from 0.38793 to 0.38641, saving model to weights_best.hdf5\n",
            "Epoch 26/300\n",
            "11800/12628 [===========================>..] - ETA: 0s - loss: 0.3766 - acc: 0.8305"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3773 - acc: 0.8290\n",
            "\n",
            "Epoch 00026: loss improved from 0.38641 to 0.37729, saving model to weights_best.hdf5\n",
            "Epoch 27/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3709 - acc: 0.8398\n",
            "\n",
            "Epoch 00027: loss improved from 0.37729 to 0.37085, saving model to weights_best.hdf5\n",
            "Epoch 28/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3619 - acc: 0.8408\n",
            "\n",
            "Epoch 00028: loss improved from 0.37085 to 0.36190, saving model to weights_best.hdf5\n",
            "Epoch 29/300\n",
            "  700/12628 [>.............................] - ETA: 13s - loss: 0.3771 - acc: 0.8286"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3551 - acc: 0.8489\n",
            "\n",
            "Epoch 00029: loss improved from 0.36190 to 0.35513, saving model to weights_best.hdf5\n",
            "Epoch 30/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3449 - acc: 0.8522\n",
            "\n",
            "Epoch 00030: loss improved from 0.35513 to 0.34486, saving model to weights_best.hdf5\n",
            "Epoch 31/300\n",
            "11800/12628 [===========================>..] - ETA: 0s - loss: 0.3382 - acc: 0.8561"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3409 - acc: 0.8547\n",
            "\n",
            "Epoch 00031: loss improved from 0.34486 to 0.34089, saving model to weights_best.hdf5\n",
            "Epoch 32/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3412 - acc: 0.8518\n",
            "\n",
            "Epoch 00032: loss did not improve\n",
            "Epoch 33/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3248 - acc: 0.8599\n",
            "\n",
            "Epoch 00033: loss improved from 0.34089 to 0.32482, saving model to weights_best.hdf5\n",
            "Epoch 34/300\n",
            " 1900/12628 [===>..........................] - ETA: 11s - loss: 0.3139 - acc: 0.8621"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3195 - acc: 0.8667\n",
            "\n",
            "Epoch 00034: loss improved from 0.32482 to 0.31950, saving model to weights_best.hdf5\n",
            "Epoch 35/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3094 - acc: 0.8681\n",
            "\n",
            "Epoch 00035: loss improved from 0.31950 to 0.30944, saving model to weights_best.hdf5\n",
            "Epoch 36/300\n",
            "12000/12628 [===========================>..] - ETA: 0s - loss: 0.3043 - acc: 0.8718"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.3046 - acc: 0.8712\n",
            "\n",
            "Epoch 00036: loss improved from 0.30944 to 0.30460, saving model to weights_best.hdf5\n",
            "Epoch 37/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2990 - acc: 0.8754\n",
            "\n",
            "Epoch 00037: loss improved from 0.30460 to 0.29900, saving model to weights_best.hdf5\n",
            "Epoch 38/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2921 - acc: 0.8770\n",
            "\n",
            "Epoch 00038: loss improved from 0.29900 to 0.29210, saving model to weights_best.hdf5\n",
            "Epoch 39/300\n",
            "  700/12628 [>.............................] - ETA: 12s - loss: 0.3099 - acc: 0.8686"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2862 - acc: 0.8785\n",
            "\n",
            "Epoch 00039: loss improved from 0.29210 to 0.28624, saving model to weights_best.hdf5\n",
            "Epoch 40/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2777 - acc: 0.8864\n",
            "\n",
            "Epoch 00040: loss improved from 0.28624 to 0.27766, saving model to weights_best.hdf5\n",
            "Epoch 41/300\n",
            "11800/12628 [===========================>..] - ETA: 0s - loss: 0.2609 - acc: 0.8915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2618 - acc: 0.8913\n",
            "\n",
            "Epoch 00041: loss improved from 0.27766 to 0.26180, saving model to weights_best.hdf5\n",
            "Epoch 42/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2672 - acc: 0.8899\n",
            "\n",
            "Epoch 00042: loss did not improve\n",
            "Epoch 43/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2590 - acc: 0.8904\n",
            "\n",
            "Epoch 00043: loss improved from 0.26180 to 0.25896, saving model to weights_best.hdf5\n",
            "Epoch 44/300\n",
            " 1900/12628 [===>..........................] - ETA: 11s - loss: 0.2357 - acc: 0.9047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2471 - acc: 0.8975\n",
            "\n",
            "Epoch 00044: loss improved from 0.25896 to 0.24710, saving model to weights_best.hdf5\n",
            "Epoch 45/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2429 - acc: 0.8998\n",
            "\n",
            "Epoch 00045: loss improved from 0.24710 to 0.24288, saving model to weights_best.hdf5\n",
            "Epoch 46/300\n",
            "12000/12628 [===========================>..] - ETA: 0s - loss: 0.2366 - acc: 0.9032"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2385 - acc: 0.9025\n",
            "\n",
            "Epoch 00046: loss improved from 0.24288 to 0.23848, saving model to weights_best.hdf5\n",
            "Epoch 47/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2332 - acc: 0.9038\n",
            "\n",
            "Epoch 00047: loss improved from 0.23848 to 0.23323, saving model to weights_best.hdf5\n",
            "Epoch 48/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2202 - acc: 0.9123\n",
            "\n",
            "Epoch 00048: loss improved from 0.23323 to 0.22021, saving model to weights_best.hdf5\n",
            "Epoch 49/300\n",
            "  600/12628 [>.............................] - ETA: 12s - loss: 0.2078 - acc: 0.9117"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2250 - acc: 0.9080\n",
            "\n",
            "Epoch 00049: loss did not improve\n",
            "Epoch 50/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2158 - acc: 0.9139\n",
            "\n",
            "Epoch 00050: loss improved from 0.22021 to 0.21579, saving model to weights_best.hdf5\n",
            "Epoch 51/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2063 - acc: 0.9210\n",
            "\n",
            "Epoch 00051: loss improved from 0.21579 to 0.20630, saving model to weights_best.hdf5\n",
            "Epoch 52/300\n",
            " 1400/12628 [==>...........................] - ETA: 12s - loss: 0.2050 - acc: 0.9214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.2022 - acc: 0.9200\n",
            "\n",
            "Epoch 00052: loss improved from 0.20630 to 0.20216, saving model to weights_best.hdf5\n",
            "Epoch 53/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1979 - acc: 0.9235\n",
            "\n",
            "Epoch 00053: loss improved from 0.20216 to 0.19794, saving model to weights_best.hdf5\n",
            "Epoch 54/300\n",
            "12000/12628 [===========================>..] - ETA: 0s - loss: 0.1903 - acc: 0.9243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1879 - acc: 0.9251\n",
            "\n",
            "Epoch 00054: loss improved from 0.19794 to 0.18786, saving model to weights_best.hdf5\n",
            "Epoch 55/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1838 - acc: 0.9297\n",
            "\n",
            "Epoch 00055: loss improved from 0.18786 to 0.18382, saving model to weights_best.hdf5\n",
            "Epoch 56/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1796 - acc: 0.9309\n",
            "\n",
            "Epoch 00056: loss improved from 0.18382 to 0.17962, saving model to weights_best.hdf5\n",
            "Epoch 57/300\n",
            "  700/12628 [>.............................] - ETA: 13s - loss: 0.1887 - acc: 0.9243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1768 - acc: 0.9335\n",
            "\n",
            "Epoch 00057: loss improved from 0.17962 to 0.17681, saving model to weights_best.hdf5\n",
            "Epoch 58/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1717 - acc: 0.9352\n",
            "\n",
            "Epoch 00058: loss improved from 0.17681 to 0.17167, saving model to weights_best.hdf5\n",
            "Epoch 59/300\n",
            "11800/12628 [===========================>..] - ETA: 0s - loss: 0.1645 - acc: 0.9391"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1656 - acc: 0.9385\n",
            "\n",
            "Epoch 00059: loss improved from 0.17167 to 0.16563, saving model to weights_best.hdf5\n",
            "Epoch 60/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1648 - acc: 0.9349\n",
            "\n",
            "Epoch 00060: loss improved from 0.16563 to 0.16475, saving model to weights_best.hdf5\n",
            "Epoch 61/300\n",
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1576 - acc: 0.9389\n",
            "\n",
            "Epoch 00061: loss improved from 0.16475 to 0.15756, saving model to weights_best.hdf5\n",
            "Epoch 62/300\n",
            "  700/12628 [>.............................] - ETA: 12s - loss: 0.1454 - acc: 0.9400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 14s 1ms/step - loss: 0.1501 - acc: 0.9442\n",
            "\n",
            "Epoch 00062: loss improved from 0.15756 to 0.15015, saving model to weights_best.hdf5\n",
            "Epoch 63/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1545 - acc: 0.9400\n",
            "\n",
            "Epoch 00063: loss did not improve\n",
            "Epoch 64/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1539 - acc: 0.9405\n",
            "\n",
            "Epoch 00064: loss did not improve\n",
            "Epoch 65/300\n",
            "  300/12628 [..............................] - ETA: 13s - loss: 0.1172 - acc: 0.9600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1539 - acc: 0.9413\n",
            "\n",
            "Epoch 00065: loss did not improve\n",
            "Epoch 66/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1493 - acc: 0.9421\n",
            "\n",
            "Epoch 00066: loss improved from 0.15015 to 0.14927, saving model to weights_best.hdf5\n",
            "Epoch 67/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1430 - acc: 0.9451\n",
            "\n",
            "Epoch 00067: loss improved from 0.14927 to 0.14296, saving model to weights_best.hdf5\n",
            "Epoch 68/300\n",
            " 1300/12628 [==>...........................] - ETA: 12s - loss: 0.1034 - acc: 0.9608"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1385 - acc: 0.9481\n",
            "\n",
            "Epoch 00068: loss improved from 0.14296 to 0.13851, saving model to weights_best.hdf5\n",
            "Epoch 69/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1317 - acc: 0.9496\n",
            "\n",
            "Epoch 00069: loss improved from 0.13851 to 0.13165, saving model to weights_best.hdf5\n",
            "Epoch 70/300\n",
            "11900/12628 [===========================>..] - ETA: 0s - loss: 0.1236 - acc: 0.9541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1241 - acc: 0.9540\n",
            "\n",
            "Epoch 00070: loss improved from 0.13165 to 0.12407, saving model to weights_best.hdf5\n",
            "Epoch 71/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1279 - acc: 0.9526\n",
            "\n",
            "Epoch 00071: loss did not improve\n",
            "Epoch 72/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1299 - acc: 0.9522\n",
            "\n",
            "Epoch 00072: loss did not improve\n",
            "Epoch 73/300\n",
            " 2100/12628 [===>..........................] - ETA: 11s - loss: 0.1012 - acc: 0.9614"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1217 - acc: 0.9541\n",
            "\n",
            "Epoch 00073: loss improved from 0.12407 to 0.12171, saving model to weights_best.hdf5\n",
            "Epoch 74/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1254 - acc: 0.9522\n",
            "\n",
            "Epoch 00074: loss did not improve\n",
            "Epoch 75/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1120 - acc: 0.9572\n",
            "\n",
            "Epoch 00075: loss improved from 0.12171 to 0.11202, saving model to weights_best.hdf5\n",
            "Epoch 76/300\n",
            "  500/12628 [>.............................] - ETA: 12s - loss: 0.1693 - acc: 0.9460"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1137 - acc: 0.9566\n",
            "\n",
            "Epoch 00076: loss did not improve\n",
            "Epoch 77/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1115 - acc: 0.9587\n",
            "\n",
            "Epoch 00077: loss improved from 0.11202 to 0.11155, saving model to weights_best.hdf5\n",
            "Epoch 78/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1187 - acc: 0.9543\n",
            "\n",
            "Epoch 00078: loss did not improve\n",
            "Epoch 79/300\n",
            " 1600/12628 [==>...........................] - ETA: 11s - loss: 0.1013 - acc: 0.9631"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1095 - acc: 0.9591\n",
            "\n",
            "Epoch 00079: loss improved from 0.11155 to 0.10949, saving model to weights_best.hdf5\n",
            "Epoch 80/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1074 - acc: 0.9603\n",
            "\n",
            "Epoch 00080: loss improved from 0.10949 to 0.10736, saving model to weights_best.hdf5\n",
            "Epoch 81/300\n",
            "12000/12628 [===========================>..] - ETA: 0s - loss: 0.1062 - acc: 0.9601"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1053 - acc: 0.9606\n",
            "\n",
            "Epoch 00081: loss improved from 0.10736 to 0.10534, saving model to weights_best.hdf5\n",
            "Epoch 82/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.1042 - acc: 0.9607\n",
            "\n",
            "Epoch 00082: loss improved from 0.10534 to 0.10418, saving model to weights_best.hdf5\n",
            "Epoch 83/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0943 - acc: 0.9650\n",
            "\n",
            "Epoch 00083: loss improved from 0.10418 to 0.09428, saving model to weights_best.hdf5\n",
            "Epoch 84/300\n",
            "  600/12628 [>.............................] - ETA: 12s - loss: 0.0850 - acc: 0.9650"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0951 - acc: 0.9617\n",
            "\n",
            "Epoch 00084: loss did not improve\n",
            "Epoch 85/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0956 - acc: 0.9648\n",
            "\n",
            "Epoch 00085: loss did not improve\n",
            "Epoch 86/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0960 - acc: 0.9641\n",
            "\n",
            "Epoch 00086: loss did not improve\n",
            "Epoch 87/300\n",
            " 3100/12628 [======>.......................] - ETA: 9s - loss: 0.0881 - acc: 0.9632 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0885 - acc: 0.9657\n",
            "\n",
            "Epoch 00087: loss improved from 0.09428 to 0.08852, saving model to weights_best.hdf5\n",
            "Epoch 88/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0958 - acc: 0.9648\n",
            "\n",
            "Epoch 00088: loss did not improve\n",
            "Epoch 89/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0896 - acc: 0.9656\n",
            "\n",
            "Epoch 00089: loss did not improve\n",
            "Epoch 90/300\n",
            "  800/12628 [>.............................] - ETA: 12s - loss: 0.0673 - acc: 0.9788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0879 - acc: 0.9666\n",
            "\n",
            "Epoch 00090: loss improved from 0.08852 to 0.08793, saving model to weights_best.hdf5\n",
            "Epoch 91/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0999 - acc: 0.9607\n",
            "\n",
            "Epoch 00091: loss did not improve\n",
            "Epoch 92/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0786 - acc: 0.9698\n",
            "\n",
            "Epoch 00092: loss improved from 0.08793 to 0.07855, saving model to weights_best.hdf5\n",
            "Epoch 93/300\n",
            "  200/12628 [..............................] - ETA: 12s - loss: 0.1340 - acc: 0.9600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0837 - acc: 0.9691\n",
            "\n",
            "Epoch 00093: loss did not improve\n",
            "Epoch 94/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0852 - acc: 0.9687\n",
            "\n",
            "Epoch 00094: loss did not improve\n",
            "Epoch 95/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0847 - acc: 0.9662\n",
            "\n",
            "Epoch 00095: loss did not improve\n",
            "Epoch 96/300\n",
            " 3000/12628 [======>.......................] - ETA: 10s - loss: 0.0849 - acc: 0.9687"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0805 - acc: 0.9700\n",
            "\n",
            "Epoch 00096: loss did not improve\n",
            "Epoch 97/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0787 - acc: 0.9701\n",
            "\n",
            "Epoch 00097: loss did not improve\n",
            "Epoch 98/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0806 - acc: 0.9683\n",
            "\n",
            "Epoch 00098: loss did not improve\n",
            "Epoch 99/300\n",
            " 3600/12628 [=======>......................] - ETA: 9s - loss: 0.0799 - acc: 0.9692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0763 - acc: 0.9720\n",
            "\n",
            "Epoch 00099: loss improved from 0.07855 to 0.07632, saving model to weights_best.hdf5\n",
            "Epoch 100/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0815 - acc: 0.9701\n",
            "\n",
            "Epoch 00100: loss did not improve\n",
            "Epoch 101/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0713 - acc: 0.9712\n",
            "\n",
            "Epoch 00101: loss improved from 0.07632 to 0.07134, saving model to weights_best.hdf5\n",
            "Epoch 102/300\n",
            "  700/12628 [>.............................] - ETA: 12s - loss: 0.0459 - acc: 0.9843"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0740 - acc: 0.9727\n",
            "\n",
            "Epoch 00102: loss did not improve\n",
            "Epoch 103/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0842 - acc: 0.9674\n",
            "\n",
            "Epoch 00103: loss did not improve\n",
            "Epoch 104/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0773 - acc: 0.9720\n",
            "\n",
            "Epoch 00104: loss did not improve\n",
            "Epoch 105/300\n",
            " 2900/12628 [=====>........................] - ETA: 10s - loss: 0.0629 - acc: 0.9762"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0702 - acc: 0.9736\n",
            "\n",
            "Epoch 00105: loss improved from 0.07134 to 0.07019, saving model to weights_best.hdf5\n",
            "Epoch 106/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0625 - acc: 0.9768\n",
            "\n",
            "Epoch 00106: loss improved from 0.07019 to 0.06249, saving model to weights_best.hdf5\n",
            "Epoch 107/300\n",
            "12100/12628 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9733"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0693 - acc: 0.9736\n",
            "\n",
            "Epoch 00107: loss did not improve\n",
            "Epoch 108/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0711 - acc: 0.9719\n",
            "\n",
            "Epoch 00108: loss did not improve\n",
            "Epoch 109/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0665 - acc: 0.9739\n",
            "\n",
            "Epoch 00109: loss did not improve\n",
            "Epoch 110/300\n",
            " 5000/12628 [==========>...................] - ETA: 7s - loss: 0.0567 - acc: 0.9800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0670 - acc: 0.9755\n",
            "\n",
            "Epoch 00110: loss did not improve\n",
            "Epoch 111/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0641 - acc: 0.9759\n",
            "\n",
            "Epoch 00111: loss did not improve\n",
            "Epoch 112/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0615 - acc: 0.9773\n",
            "\n",
            "Epoch 00112: loss improved from 0.06249 to 0.06145, saving model to weights_best.hdf5\n",
            "Epoch 113/300\n",
            " 3300/12628 [======>.......................] - ETA: 9s - loss: 0.0636 - acc: 0.9770"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0653 - acc: 0.9756\n",
            "\n",
            "Epoch 00113: loss did not improve\n",
            "Epoch 114/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0607 - acc: 0.9775\n",
            "\n",
            "Epoch 00114: loss improved from 0.06145 to 0.06072, saving model to weights_best.hdf5\n",
            "Epoch 115/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0756 - acc: 0.9736\n",
            "\n",
            "Epoch 00115: loss did not improve\n",
            "Epoch 116/300\n",
            " 1800/12628 [===>..........................] - ETA: 11s - loss: 0.0478 - acc: 0.9856"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0579 - acc: 0.9780\n",
            "\n",
            "Epoch 00116: loss improved from 0.06072 to 0.05789, saving model to weights_best.hdf5\n",
            "Epoch 117/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0666 - acc: 0.9748\n",
            "\n",
            "Epoch 00117: loss did not improve\n",
            "Epoch 118/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0576 - acc: 0.9782\n",
            "\n",
            "Epoch 00118: loss improved from 0.05789 to 0.05762, saving model to weights_best.hdf5\n",
            "Epoch 119/300\n",
            "  300/12628 [..............................] - ETA: 12s - loss: 0.0358 - acc: 0.9833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0661 - acc: 0.9740\n",
            "\n",
            "Epoch 00119: loss did not improve\n",
            "Epoch 120/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0614 - acc: 0.9775\n",
            "\n",
            "Epoch 00120: loss did not improve\n",
            "Epoch 121/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0587 - acc: 0.9791\n",
            "\n",
            "Epoch 00121: loss did not improve\n",
            "Epoch 122/300\n",
            " 2900/12628 [=====>........................] - ETA: 10s - loss: 0.0633 - acc: 0.9762"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0551 - acc: 0.9795\n",
            "\n",
            "Epoch 00122: loss improved from 0.05762 to 0.05512, saving model to weights_best.hdf5\n",
            "Epoch 123/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0578 - acc: 0.9776\n",
            "\n",
            "Epoch 00123: loss did not improve\n",
            "Epoch 124/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0590 - acc: 0.9780\n",
            "\n",
            "Epoch 00124: loss did not improve\n",
            "Epoch 125/300\n",
            "  600/12628 [>.............................] - ETA: 12s - loss: 0.0742 - acc: 0.9717"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0567 - acc: 0.9781\n",
            "\n",
            "Epoch 00125: loss did not improve\n",
            "Epoch 126/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0581 - acc: 0.9777\n",
            "\n",
            "Epoch 00126: loss did not improve\n",
            "Epoch 127/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0540 - acc: 0.9793\n",
            "\n",
            "Epoch 00127: loss improved from 0.05512 to 0.05398, saving model to weights_best.hdf5\n",
            "Epoch 128/300\n",
            " 2500/12628 [====>.........................] - ETA: 10s - loss: 0.0554 - acc: 0.9760"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0501 - acc: 0.9816\n",
            "\n",
            "Epoch 00128: loss improved from 0.05398 to 0.05006, saving model to weights_best.hdf5\n",
            "Epoch 129/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0483 - acc: 0.9817\n",
            "\n",
            "Epoch 00129: loss improved from 0.05006 to 0.04826, saving model to weights_best.hdf5\n",
            "Epoch 130/300\n",
            "11500/12628 [==========================>...] - ETA: 1s - loss: 0.0592 - acc: 0.9771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0592 - acc: 0.9768\n",
            "\n",
            "Epoch 00130: loss did not improve\n",
            "Epoch 131/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0559 - acc: 0.9781\n",
            "\n",
            "Epoch 00131: loss did not improve\n",
            "Epoch 132/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0637 - acc: 0.9769\n",
            "\n",
            "Epoch 00132: loss did not improve\n",
            "Epoch 133/300\n",
            " 4500/12628 [=========>....................] - ETA: 8s - loss: 0.0464 - acc: 0.9824"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0558 - acc: 0.9796\n",
            "\n",
            "Epoch 00133: loss did not improve\n",
            "Epoch 134/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0533 - acc: 0.9800\n",
            "\n",
            "Epoch 00134: loss did not improve\n",
            "Epoch 135/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0549 - acc: 0.9792\n",
            "\n",
            "Epoch 00135: loss did not improve\n",
            "Epoch 136/300\n",
            " 2900/12628 [=====>........................] - ETA: 9s - loss: 0.0483 - acc: 0.9838 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0483 - acc: 0.9806\n",
            "\n",
            "Epoch 00136: loss did not improve\n",
            "Epoch 137/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0502 - acc: 0.9815\n",
            "\n",
            "Epoch 00137: loss did not improve\n",
            "Epoch 138/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0447 - acc: 0.9835\n",
            "\n",
            "Epoch 00138: loss improved from 0.04826 to 0.04470, saving model to weights_best.hdf5\n",
            "Epoch 139/300\n",
            " 2600/12628 [=====>........................] - ETA: 10s - loss: 0.0396 - acc: 0.9854"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0421 - acc: 0.9839\n",
            "\n",
            "Epoch 00139: loss improved from 0.04470 to 0.04214, saving model to weights_best.hdf5\n",
            "Epoch 140/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0470 - acc: 0.9829\n",
            "\n",
            "Epoch 00140: loss did not improve\n",
            "Epoch 141/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0542 - acc: 0.9797\n",
            "\n",
            "Epoch 00141: loss did not improve\n",
            "Epoch 142/300\n",
            "  200/12628 [..............................] - ETA: 13s - loss: 0.0357 - acc: 0.9800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0553 - acc: 0.9800\n",
            "\n",
            "Epoch 00142: loss did not improve\n",
            "Epoch 143/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0555 - acc: 0.9800\n",
            "\n",
            "Epoch 00143: loss did not improve\n",
            "Epoch 144/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0559 - acc: 0.9798\n",
            "\n",
            "Epoch 00144: loss did not improve\n",
            "Epoch 145/300\n",
            " 2600/12628 [=====>........................] - ETA: 10s - loss: 0.0531 - acc: 0.9788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0496 - acc: 0.9814\n",
            "\n",
            "Epoch 00145: loss did not improve\n",
            "Epoch 146/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0497 - acc: 0.9815\n",
            "\n",
            "Epoch 00146: loss did not improve\n",
            "Epoch 147/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0441 - acc: 0.9836\n",
            "\n",
            "Epoch 00147: loss did not improve\n",
            "Epoch 148/300\n",
            " 2400/12628 [====>.........................] - ETA: 10s - loss: 0.0371 - acc: 0.9892"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0539 - acc: 0.9800\n",
            "\n",
            "Epoch 00148: loss did not improve\n",
            "Epoch 149/300\n",
            "12628/12628 [==============================] - 13s 1ms/step - loss: 0.0457 - acc: 0.9834\n",
            "\n",
            "Epoch 00149: loss did not improve\n",
            "Epoch 00149: early stopping\n",
            "3158/3158 [==============================] - 3s 1ms/step\n",
            "\n",
            "acc: 72.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Bim5mKUxuti",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "drive = authenticate_drive()\n",
        "\n",
        "uploaded = drive.CreateFile({'title': filepath})\n",
        "uploaded.SetContentFile(filepath)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "print('Done uploading weights')\n",
        "\n",
        "if finished_training:\n",
        "  uploaded_model = drive.CreateFile({'title': model_name})\n",
        "  uploaded_model.SetContentFile(model_name)\n",
        "  uploaded_model.Upload()\n",
        "  print('Uploaded file with ID {}'.format(uploaded_model.get('id')))\n",
        "  print('Done uploading model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JO49khluSvq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#using the model\n",
        "\n",
        "done = False\n",
        "while done == False:\n",
        "  sentence = input('Input sentence: ')\n",
        "  \n",
        "  sentence_encoding = token.texts_to_sequences([sentence])\n",
        "  padded_sentence = sequence.pad_sequences(sentence_encoding, maxlen=max_len)\n",
        "  \n",
        "  prediction = model.predict(np.array(padded_sentence))\n",
        "  if prediction[0] == 1:\n",
        "    print(prediction[0])\n",
        "    print('Positive')\n",
        "  elif prediction[0] == 0:\n",
        "    print(prediction[0])\n",
        "    print('Negative')\n",
        "  \n",
        "  finish = input('Do you still want to input another text? [y/n]')\n",
        "  if finish == 'N' or finish == 'n':\n",
        "    done = True"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}